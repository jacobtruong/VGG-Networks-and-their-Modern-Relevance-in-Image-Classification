{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, Subset\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm\n",
    "import uuid\n",
    "import pickle\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((448,448)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(10),\n",
    "                                transforms.RandomAffine(0, shear=5, scale=(0.8,1.2)), \n",
    "                              #   transforms.RandomGrayscale(p=0.1), \n",
    "                                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.4815, 0.4578, 0.4082), (0.2686, 0.2613, 0.2758)), \n",
    "                                      ])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize((448,448)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.4815, 0.4578, 0.4082), (0.2686, 0.2613, 0.2758)),\n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, transform: transforms.Compose):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "def stratified_split(dataset, val_split=0.):\n",
    "    targets = np.array(dataset.targets)\n",
    "\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(targets.shape[0]),\n",
    "        test_size=val_split,\n",
    "        stratify=targets\n",
    "    )\n",
    "\n",
    "    # train_dataset = Subset(dataset, indices=train_indices)\n",
    "    # val_dataset = Subset(dataset, indices=val_indices)\n",
    "    # return train_dataset, val_dataset\n",
    "\n",
    "    return train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset separately for training and validation\n",
    "dataset = datasets.ImageFolder(root = \"./final_data\")\n",
    "\n",
    "# train_indices, val_indices = stratified_split(dataset, val_split=0.2)\n",
    "\n",
    "# Loading the indices from the saved pickle file to ensure the same split is used across different models\n",
    "with open('train_indices.pkl', 'rb') as f:\n",
    "    train_indices = pickle.load(f)\n",
    "\n",
    "with open('val_indices.pkl', 'rb') as f:\n",
    "    val_indices = pickle.load(f)\n",
    "\n",
    "# Split the dataset into training and validation\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "transformed_train = TransformedDataset(train_dataset, transform)\n",
    "transformed_val = TransformedDataset(val_dataset, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(transformed_train, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(transformed_val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store all datapoints from transformed_train\n",
    "# train_images = []\n",
    "# train_labels = []\n",
    "# for i in range(len(transformed_train)):\n",
    "#     img, label = transformed_train[i]\n",
    "#     train_images.append(img)\n",
    "#     train_labels.append(label)\n",
    "\n",
    "# # Store all datapoints from transformed_val\n",
    "# val_images = []\n",
    "# val_labels = []\n",
    "# for i in range(len(transformed_val)):\n",
    "#     img, label = transformed_val[i]\n",
    "#     val_images.append(img)\n",
    "#     val_labels.append(label)\n",
    "\n",
    "# train_full = (torch.stack(train_images).to(device), torch.tensor(train_labels).to(device))\n",
    "# val_full = (torch.stack(val_images).to(device), torch.tensor(val_labels).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Vision Transformer model\n",
    "class CustomViTModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomViTModel, self).__init__()\n",
    "        # Load the pre-trained ViT model\n",
    "        self.base_vit = timm.create_model('eva02_large_patch14_448.mim_m38m_ft_in22k_in1k', pretrained=True)\n",
    "        data_config = timm.data.resolve_model_data_config(self.base_vit)\n",
    "        self.transforms_train = timm.data.create_transform(**data_config, is_training=True)\n",
    "        self.transforms_val = timm.data.create_transform(**data_config, is_training=False)\n",
    "        \n",
    "        # Freeze the base model\n",
    "        for param in self.base_vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the classifier head\n",
    "        self.base_vit.head = nn.Sequential(\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(self.base_vit.head.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_vit(x)\n",
    "\n",
    "# Instantiate the model\n",
    "num_classes = len(dataset.classes)  # Adjust according to your specific number of classes\n",
    "model = CustomViTModel(num_classes=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "model_paradigm = 'ViT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(output, target, k=5):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(k, 1, True, True)  # Get top-k predictions\n",
    "    pred = pred.t()  # Transpose predictions for comparison\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))  # Compare predictions with target\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)  # Calculate correct top-k\n",
    "    return correct_k.mul_(1.0 / batch_size).detach()  # Calculate top-k accuracy\n",
    "\n",
    "def evaluate(model, loss_fn, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top_1_accuracy = 0\n",
    "    top_5_accuracy = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc = \"Validating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batchX, batchY in progress_bar:\n",
    "            batchX, batchY = batchX.to(device), batchY.to(device)\n",
    "\n",
    "            output = model(batchX)\n",
    "            predicted_labels = torch.argmax(output, dim = 1)\n",
    "\n",
    "            loss += loss_fn(output, batchY).detach() * batchX.size(0)\n",
    "            correct += (predicted_labels == batchY.type(torch.long)).sum().detach()\n",
    "            total += batchX.size(0)\n",
    "            top_1_accuracy += top_k_accuracy(output, batchY, k=1) * batchX.size(0)\n",
    "            top_5_accuracy += top_k_accuracy(output, batchY, k=5) * batchX.size(0)\n",
    "    \n",
    "    return loss.item() / total, correct.item() / total, top_1_accuracy.item() / total, top_5_accuracy.item() / total\n",
    "\n",
    "def evaluate_all(model, loss_fn, allX, allY):\n",
    "    model.eval()\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    top_1_accuracy = 0\n",
    "    top_5_accuracy = 0\n",
    "\n",
    "    allX, allY = allX.to(device), allY.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(allX)\n",
    "        predicted_labels = torch.argmax(output, dim = 1)\n",
    "\n",
    "        loss += loss_fn(output, allY.type(torch.long)).detach()\n",
    "        correct += (predicted_labels == allY.type(torch.long)).sum().detach()\n",
    "        top_1_accuracy += top_k_accuracy(output, allY, k=1)\n",
    "        top_5_accuracy += top_k_accuracy(output, allY, k=5)\n",
    "    \n",
    "    return loss.item(), correct.item() / allX.size(0), top_1_accuracy.item(), top_5_accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(his):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ln1 = ax.plot(his['train_loss'], 'b--',label='loss')\n",
    "    ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
    "    ax.set_ylabel('loss', color='blue')\n",
    "    ax.tick_params(axis='y', colors=\"blue\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ln3 = ax2.plot(his['train_acc'], 'r--',label='accuracy')\n",
    "    ln4 = ax2.plot(his['val_acc'], 'r-',label='val_accuracy')\n",
    "    ax2.set_ylabel('accuracy', color='red')\n",
    "    ax2.tick_params(axis='y', colors=\"red\")\n",
    "\n",
    "    lns = ln1 + ln2 + ln3 + ln4\n",
    "    labels = [l.get_label() for l in lns]\n",
    "    ax.legend(lns, labels, loc=7)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {\"Adam\":optim.Adam, \"Adadelta\":optim.Adadelta, \"Adagrad\":optim.Adagrad,\n",
    "              \"Adamax\":optim.Adamax, \"AdamW\": optim.AdamW, \"ASGD\":optim.ASGD,\n",
    "              \"NAdam\":optim.NAdam, \"RMSprop\":optim.RMSprop, \"RAdam\":optim.RAdam,\n",
    "              \"Rprop\": optim.Rprop, \"SGD\":optim.SGD}\n",
    "\n",
    "\n",
    "# Loss and optimiser\n",
    "# NOTE: Please note that different learning_rates were used for different models at different stages of experimentation.\n",
    "# learning_rate = 0.0001\n",
    "learning_rate = 0.0001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = optim_dict[\"Adam\"](model.parameters(), lr=learning_rate)\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/144 [00:00<?, ?it/s]c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\timm\\models\\eva.py:138: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "Epoch 1:  22%|██▏       | 32/144 [00:28<01:38,  1.14it/s]c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 144/144 [02:03<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8932 - Accuracy: 75.5493% - Val Loss: 0.4557 - Val Accuracy: 85.9130% - Top 1 Accuracy: 0.8591304347826086 - Top 5 Accuracy: 0.9973913043478261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3868 - Accuracy: 88.0574% - Val Loss: 0.3302 - Val Accuracy: 89.8261% - Top 1 Accuracy: 0.8982608695652174 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:51<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3069 - Accuracy: 90.2763% - Val Loss: 0.2880 - Val Accuracy: 91.0435% - Top 1 Accuracy: 0.9104347826086957 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 144/144 [02:12<00:00,  1.09it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2647 - Accuracy: 91.5815% - Val Loss: 0.2744 - Val Accuracy: 91.0435% - Top 1 Accuracy: 0.9104347826086957 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 144/144 [02:05<00:00,  1.14it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2411 - Accuracy: 92.1906% - Val Loss: 0.2594 - Val Accuracy: 91.1304% - Top 1 Accuracy: 0.9113043478260869 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 144/144 [02:05<00:00,  1.15it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2200 - Accuracy: 92.9954% - Val Loss: 0.2402 - Val Accuracy: 91.2174% - Top 1 Accuracy: 0.9121739130434783 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 144/144 [02:04<00:00,  1.15it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1985 - Accuracy: 93.7133% - Val Loss: 0.2424 - Val Accuracy: 92.0000% - Top 1 Accuracy: 0.92 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1881 - Accuracy: 93.6915% - Val Loss: 0.2296 - Val Accuracy: 91.7391% - Top 1 Accuracy: 0.9173913043478261 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1706 - Accuracy: 94.9532% - Val Loss: 0.2316 - Val Accuracy: 90.8696% - Top 1 Accuracy: 0.908695652173913 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 144/144 [02:04<00:00,  1.15it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1618 - Accuracy: 94.6269% - Val Loss: 0.2215 - Val Accuracy: 92.6087% - Top 1 Accuracy: 0.9260869565217391 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1539 - Accuracy: 94.9967% - Val Loss: 0.2369 - Val Accuracy: 89.8261% - Top 1 Accuracy: 0.8982608695652174 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1386 - Accuracy: 95.5188% - Val Loss: 0.2313 - Val Accuracy: 91.3913% - Top 1 Accuracy: 0.9139130434782609 - Top 5 Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1385 - Accuracy: 95.5406% - Val Loss: 0.2258 - Val Accuracy: 92.1739% - Top 1 Accuracy: 0.9217391304347826 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1284 - Accuracy: 95.8451% - Val Loss: 0.2294 - Val Accuracy: 91.5652% - Top 1 Accuracy: 0.9156521739130434 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1198 - Accuracy: 96.3454% - Val Loss: 0.2440 - Val Accuracy: 90.9565% - Top 1 Accuracy: 0.9095652173913044 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1134 - Accuracy: 96.4542% - Val Loss: 0.2198 - Val Accuracy: 91.3043% - Top 1 Accuracy: 0.9130434782608695 - Top 5 Accuracy: 0.9982608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 144/144 [02:04<00:00,  1.15it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1084 - Accuracy: 96.5847% - Val Loss: 0.2180 - Val Accuracy: 92.1739% - Top 1 Accuracy: 0.9217391304347826 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1006 - Accuracy: 96.8675% - Val Loss: 0.2237 - Val Accuracy: 91.7391% - Top 1 Accuracy: 0.9173913043478261 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0992 - Accuracy: 96.9328% - Val Loss: 0.2183 - Val Accuracy: 91.5652% - Top 1 Accuracy: 0.9156521739130434 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 144/144 [02:04<00:00,  1.16it/s]\n",
      "Validating: 100%|██████████| 36/36 [00:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0950 - Accuracy: 97.0198% - Val Loss: 0.2298 - Val Accuracy: 92.0870% - Top 1 Accuracy: 0.9208695652173913 - Top 5 Accuracy: 0.9991304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:  18%|█▊        | 26/144 [00:22<01:43,  1.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m---> 18\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "# Early stopping - based on validation loss\n",
    "patience_counter = 0\n",
    "patience = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in progress_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        outputs = model(X)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        running_loss += loss.detach() * X.size(0)\n",
    "        running_correct += (torch.argmax(outputs, dim = 1) == y.type(torch.long)).sum().detach()\n",
    "        total += X.size(0)\n",
    "    \n",
    "    running_loss = running_loss.item()\n",
    "    running_correct = running_correct.item()\n",
    "\n",
    "    # Evaluate the model after training is done instead of using running averages\n",
    "    # train_loss, train_acc = evaluate_all(model, loss_fn, train_full[0], train_full[1])\n",
    "    train_loss, train_acc = running_loss / total, running_correct / total\n",
    "    # val_loss, val_acc = evaluate_all(model, loss_fn, val_full[0], val_full[1])\n",
    "    val_loss, val_acc, top_1, top_5 = evaluate(model, loss_fn, val_loader)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'best_model_{model_paradigm}.pth')\n",
    "\n",
    "    # Patience is counted based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f'best_model_acc_{model_paradigm}.pth')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # torch.save(model.state_dict(), f'model_{model_paradigm}_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    tqdm.write(f'Loss: {train_loss:.4f} - Accuracy: {train_acc*100:.4f}% - Val Loss: {val_loss:.4f} - Val Accuracy: {val_acc*100:.4f}% - Top 1 Accuracy: {top_1} - Top 5 Accuracy: {top_5}')\n",
    "\n",
    "    if patience_counter == patience:\n",
    "        print(f'Early stopping: patience limit reached after epoch {epoch + 1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raven\\AppData\\Local\\Temp\\ipykernel_5728\\2034897919.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_model_acc_{model_paradigm}.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f'best_model_acc_{model_paradigm}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Train again for 20 epochs at a much lower learning rate\n",
    "learning_rate = 0.0000005\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = optim_dict[\"Adam\"](model.parameters(), lr=learning_rate)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/144 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Raven\\anaconda3\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "# Early stopping - based on validation loss\n",
    "patience_counter = 0\n",
    "patience = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in progress_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        outputs = model(X)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        running_loss += loss.detach() * X.size(0)\n",
    "        running_correct += (torch.argmax(outputs, dim = 1) == y.type(torch.long)).sum().detach()\n",
    "        total += X.size(0)\n",
    "    \n",
    "    running_loss = running_loss.item()\n",
    "    running_correct = running_correct.item()\n",
    "\n",
    "    # Evaluate the model after training is done instead of using running averages\n",
    "    # train_loss, train_acc = evaluate_all(model, loss_fn, train_full[0], train_full[1])\n",
    "    train_loss, train_acc = running_loss / total, running_correct / total\n",
    "    # val_loss, val_acc = evaluate_all(model, loss_fn, val_full[0], val_full[1])\n",
    "    val_loss, val_acc, top_1, top_5 = evaluate(model, loss_fn, val_loader)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'best_model_warmed_{model_paradigm}.pth')\n",
    "\n",
    "    # Patience is counted based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f'best_model_warmed_acc_{model_paradigm}.pth')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # torch.save(model.state_dict(), f'model_{model_paradigm}_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    tqdm.write(f'Loss: {train_loss:.4f} - Accuracy: {train_acc*100:.4f}% - Val Loss: {val_loss:.4f} - Val Accuracy: {val_acc*100:.4f}% - Top 1 Accuracy: {top_1} - Top 5 Accuracy: {top_5}')\n",
    "\n",
    "    if patience_counter == patience:\n",
    "        print(f'Early stopping: patience limit reached after epoch {epoch + 1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since train loss and accuracy was logged during training, the values are technically 1 epoch behind compared to val loss and accuracy\n",
    "# Record the train loss and accuracy after the last epoch\n",
    "train_loss, train_acc, top_1, top_5 = evaluate(model, loss_fn, train_loader)\n",
    "\n",
    "# history['train_loss'].append(train_loss)\n",
    "# history['train_acc'].append(train_acc)\n",
    "\n",
    "# # Drop the first value of train_loss and train_acc since they were logged before the first epoch\n",
    "# history['train_loss'].pop(0)\n",
    "# history['train_acc'].pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f'best_model_warmed_acc_{model_paradigm}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(root = \"./test_data\")\n",
    "transformed_test = TransformedDataset(test_dataset, val_transform)\n",
    "test_loader = DataLoader(transformed_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, top_1, top_5 = evaluate(model, loss_fn, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc*100:.4f}% - Top 1 Accuracy: {top_1} - Top 5 Accuracy: {top_5}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
